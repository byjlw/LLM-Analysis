**data_ingestion.R**
```r
# Load required libraries
library(RPostgreSQL)
library(dplyr)

# Establish connection to PostgreSQL database
con <- dbConnect(PostgreSQL(), 
                 host = "localhost", 
                 port = 5432, 
                 dbname = "sales_database", 
                 user = "username", 
                 password = "password")

# Define a function to collect and process sales data
collect_sales_data <- function() {
  # Query sales data from PostgreSQL database
  sales_data <- dbGetQuery(con, "SELECT * FROM sales_table")
  
  # Process sales data
  sales_data <- sales_data %>%
    mutate(date = as.Date(date)) %>%
    group_by(date) %>%
    summarise(sales = sum(sales))
  
  # Return processed sales data
  return(sales_data)
}

# Call the function to collect and process sales data
sales_data <- collect_sales_data()
```

**model_training.R**
```r
# Load required libraries
library(dplyr)
library(lubridate)
library(forecast)
library(nnet)

# Define a function to train a machine learning model
train_model <- function(sales_data) {
  # Split sales data into training and testing sets
  set.seed(123)
  train_index <- sample(nrow(sales_data), 0.8 * nrow(sales_data))
  train_data <- sales_data[train_index, ]
  test_data <- sales_data[-train_index, ]
  
  # Define features and target variable
  features <- data.frame(
    seasonality = sin(2 * pi * seq_along(train_data$date) / 365),
    trend = seq_along(train_data$date),
    external_factors = rnorm(nrow(train_data))
  )
  target <- train_data$sales
  
  # Train a linear regression model
  model <- lm(target ~., data = data.frame(target, features))
  
  # Return the trained model
  return(model)
}

# Call the function to train a machine learning model
model <- train_model(sales_data)
```

**model_inference.R**
```r
# Load required libraries
library(forecast)

# Define a function to make predictions using the trained model
make_predictions <- function(model, new_data) {
  # Make predictions on new data
  predictions <- predict(model, new_data)
  
  # Return the predictions
  return(predictions)
}

# Define a function to prepare new data for predictions
prepare_new_data <- function(new_date) {
  # Define features for new data
  features <- data.frame(
    seasonality = sin(2 * pi * new_date / 365),
    trend = new_date,
    external_factors = rnorm(1)
  )
  
  # Return the prepared new data
  return(features)
}

# Call the functions to prepare new data and make predictions
new_date <- as.Date("2024-01-01")
new_data <- prepare_new_data(new_date)
predictions <- make_predictions(model, new_data)
```

**analytics_dashboard.R**
```r
# Load required libraries
library(shiny)
library(ggplot2)

# Define a Shiny app for the analytics dashboard
ui <- fluidPage(
  titlePanel("Sales Forecasting and Analytics"),
  sidebarLayout(
    sidebarPanel(
      dateInput("date", "Select a date:")
    ),
    mainPanel(
      plotOutput("sales_forecast")
    )
  )
)

server <- function(input, output) {
  # Define a function to prepare new data for predictions
  prepare_new_data <- function(new_date) {
    # Define features for new data
    features <- data.frame(
      seasonality = sin(2 * pi * new_date / 365),
      trend = new_date,
      external_factors = rnorm(1)
    )
    
    # Return the prepared new data
    return(features)
  }
  
  # Define a function to make predictions using the trained model
  make_predictions <- function(model, new_data) {
    # Make predictions on new data
    predictions <- predict(model, new_data)
    
    # Return the predictions
    return(predictions)
  }
  
  # Call the functions to prepare new data and make predictions
  output$sales_forecast <- renderPlot({
    new_date <- as.Date(input$date)
    new_data <- prepare_new_data(new_date)
    predictions <- make_predictions(model, new_data)
    
    # Plot the sales forecast
    ggplot(data.frame(date = new_date, sales = predictions), aes(x = date, y = sales)) +
      geom_point() +
      geom_line()
  })
}

# Run the Shiny app
shinyApp(ui = ui, server = server)
```

**tests.R**
```r
# Load required libraries
library(testthat)

# Define tests for the data ingestion function
test_data_ingestion <- function() {
  # Test that the function returns a data frame
  expect_is(collect_sales_data(), "data.frame")
  
  # Test that the function returns a data frame with the correct columns
  expect_set_equal(colnames(collect_sales_data()), c("date", "sales"))
}

# Define tests for the model training function
test_model_training <- function() {
  # Test that the function returns a linear model
  expect_is(train_model(sales_data), "lm")
  
  # Test that the function returns a linear model with the correct coefficients
  expect_equal(coef(train_model(sales_data)), coef(model))
}

# Define tests for the model inference function
test_model_inference <- function() {
  # Test that the function returns a numeric value
  expect_is(make_predictions(model, new_data), "numeric")
  
  # Test that the function returns a numeric value within a reasonable range
  expect_gt(make_predictions(model, new_data), 0)
  expect_lt(make_predictions(model, new_data), 1000)
}

# Run the tests
test_data_ingestion()
test_model_training()
test_model_inference()
```