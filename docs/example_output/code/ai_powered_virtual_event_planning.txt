```python
# event_data_collector.py
import pandas as pd
from sqlalchemy import create_engine

class EventDataCollector:
    def __init__(self, db_url):
        self.db_url = db_url
        self.engine = create_engine(db_url)

    def collect_data(self):
        query = "SELECT * FROM event_data"
        data = pd.read_sql_query(query, self.engine)
        return data

    def preprocess_data(self, data):
        # Preprocess event data (e.g., handle missing values, normalize date/time)
        data['date'] = pd.to_datetime(data['date'])
        data['time'] = pd.to_datetime(data['time'])
        return data

# event_planner_model.py
import tensorflow as tf
from sklearn.model_selection import train_test_split
from sklearn.metrics import mean_squared_error

class EventPlannerModel:
    def __init__(self, input_shape):
        self.input_shape = input_shape
        self.model = tf.keras.models.Sequential([
            tf.keras.layers.Dense(64, activation='relu', input_shape=input_shape),
            tf.keras.layers.Dense(32, activation='relu'),
            tf.keras.layers.Dense(1)
        ])
        self.model.compile(optimizer='adam', loss='mean_squared_error')

    def train(self, X_train, y_train):
        self.model.fit(X_train, y_train, epochs=10, batch_size=32)

    def evaluate(self, X_test, y_test):
        y_pred = self.model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        return mse

# recommendation_engine.py
from sklearn.cluster import KMeans
import numpy as np

class RecommendationEngine:
    def __init__(self, n_clusters):
        self.n_clusters = n_clusters
        self.kmeans = KMeans(n_clusters=n_clusters)

    def fit(self, data):
        self.kmeans.fit(data)

    def predict(self, data):
        return self.kmeans.predict(data)

# main.py
import pandas as pd
from event_data_collector import EventDataCollector
from event_planner_model import EventPlannerModel
from recommendation_engine import RecommendationEngine

def main():
    db_url = 'postgresql://user:password@localhost/event_db'
    collector = EventDataCollector(db_url)
    data = collector.collect_data()
    data = collector.preprocess_data(data)

    # Split data into training and testing sets
    X_train, X_test, y_train, y_test = train_test_split(data.drop('target', axis=1), data['target'], test_size=0.2)

    # Train Event Planner Model
    model = EventPlannerModel((X_train.shape[1],))
    model.train(X_train, y_train)
    mse = model.evaluate(X_test, y_test)
    print(f'MSE: {mse}')

    # Implement Recommendation Engine
    engine = RecommendationEngine(n_clusters=5)
    engine.fit(data.drop('target', axis=1))
    recommendations = engine.predict(data.drop('target', axis=1))
    print(recommendations)

if __name__ == '__main__':
    main()

# tests.py
import unittest
from event_data_collector import EventDataCollector
from event_planner_model import EventPlannerModel
from recommendation_engine import RecommendationEngine

class TestEventPlanningAI(unittest.TestCase):
    def test_event_data_collector(self):
        db_url = 'postgresql://user:password@localhost/event_db'
        collector = EventDataCollector(db_url)
        data = collector.collect_data()
        self.assertIsNotNone(data)

    def test_event_planner_model(self):
        model = EventPlannerModel((10,))
        X_train = np.random.rand(100, 10)
        y_train = np.random.rand(100)
        model.train(X_train, y_train)
        self.assertIsNotNone(model.model)

    def test_recommendation_engine(self):
        engine = RecommendationEngine(n_clusters=5)
        data = np.random.rand(100, 10)
        engine.fit(data)
        recommendations = engine.predict(data)
        self.assertIsNotNone(recommendations)

if __name__ == '__main__':
    unittest.main()
```